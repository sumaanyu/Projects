{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression & Logistic regression\n",
    "\n",
    "some exercises on prediction using sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Latex, Markdown\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "import re\n",
    "from sklearn.model_selection import KFold\n",
    "#from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data:\n",
    "__Data Source__:\n",
    "Data file is named: __Energy.csv__ \n",
    "\n",
    "The dataset was created by Angeliki Xifara ( Civil/Structural Engineer) and was processed by Athanasios Tsanas, Oxford Centre for Industrial and Applied Mathematics, University of Oxford, UK).\n",
    "\n",
    "__Data Description__:\n",
    "\n",
    "The dataset contains eight attributes of a building (or features, denoted by X1...X8) and response being the heating load on the building, y1. \n",
    "\n",
    "* X1\tRelative Compactness \n",
    "* X2\tSurface Area \n",
    "* X3\tWall Area \n",
    "*  X4\tRoof Area \n",
    "*  X5\tOverall Height \n",
    "* X6\tOrientation \n",
    "*  X7\tGlazing Area \n",
    "*  X8\tGlazing Area Distribution \n",
    "*  y1\tHeating Load \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1     X2     X3      X4   X5  X6   X7  X8     Y1\n",
       "0  0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55\n",
       "1  0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55\n",
       "2  0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55\n",
       "3  0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55\n",
       "4  0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1    0\n",
      "X2    0\n",
      "X3    0\n",
      "X4    0\n",
      "X5    0\n",
      "X6    0\n",
      "X7    0\n",
      "X8    0\n",
      "Y1    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.6200</td>\n",
       "      <td>514.500</td>\n",
       "      <td>245.0</td>\n",
       "      <td>110.250</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.9800</td>\n",
       "      <td>808.500</td>\n",
       "      <td>416.5</td>\n",
       "      <td>220.500</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5.00</td>\n",
       "      <td>43.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.6825</td>\n",
       "      <td>606.375</td>\n",
       "      <td>294.0</td>\n",
       "      <td>140.875</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.75</td>\n",
       "      <td>12.9925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>673.750</td>\n",
       "      <td>318.5</td>\n",
       "      <td>183.750</td>\n",
       "      <td>5.25</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>18.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.8300</td>\n",
       "      <td>741.125</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.500</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.00</td>\n",
       "      <td>31.6675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1       X2     X3       X4    X5    X6    X7    X8       Y1\n",
       "min  0.6200  514.500  245.0  110.250  3.50  2.00  0.00  0.00   6.0100\n",
       "max  0.9800  808.500  416.5  220.500  7.00  5.00  0.40  5.00  43.1000\n",
       "25%  0.6825  606.375  294.0  140.875  3.50  2.75  0.10  1.75  12.9925\n",
       "50%  0.7500  673.750  318.5  183.750  5.25  3.50  0.25  3.00  18.9500\n",
       "75%  0.8300  741.125  343.0  220.500  7.00  4.25  0.40  4.00  31.6675"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Energy.csv')\n",
    "display(df.head())\n",
    "print(df.isnull().sum())\n",
    "(df.describe()).loc[[\"min\", 'max', '25%', '50%', '75%']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __REGRESSION__:\n",
    "\n",
    "Using the data, we want to predict \"Heating load\". The output variable is continuous. Hence, we need to use a regression algorithm.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: [84.50671242]\n",
      "coefficient values: [[-6.42688404e+01 -6.28936957e-02  3.67078157e-02 -4.98007557e-02\n",
      "   4.11430910e+00 -1.25900388e-01  1.95157505e+01  1.97512265e-01]]\n"
     ]
    }
   ],
   "source": [
    "#spt = np.random.rand(len(df)) < 0.8\n",
    "#train = df[spt]\n",
    "#test = df[~spt]\n",
    "\n",
    "X = df[['X1','X2','X3','X4','X5','X6','X7','X8']].values\n",
    "y = df[['Y1']].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 5)\n",
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train) \n",
    "print('intercept:', regressor.intercept_) \n",
    "print('coefficient values:', regressor.coef_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training RMSE: 2.879398584299829\n",
      " test RMSE: 3.0865243377757547\n"
     ]
    }
   ],
   "source": [
    "#np.sqrt(metrics.mean_squared_error\n",
    "def RMSE(pred, tar): \n",
    "    return np.sqrt(((pred - tar) ** 2).mean())\n",
    "\n",
    "q1_3_a = RMSE(regressor.predict(X_train), y_train)\n",
    "print(' training RMSE:', q1_3_a)\n",
    "\n",
    "q1_3_b = RMSE(regressor.predict(X_test), y_test)\n",
    "print(' test RMSE:', q1_3_b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the effect of amount of data on the performance of prediction model. Use varying amounts of data (100,200,300,400,500,all) from the training data used previously to train different regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 100 data points: (Training)  2.4732686300003306\n",
      "for 100 data points: (Test) 3.232989333096236\n",
      "for 200 data points: (Training)  2.6096844539978488\n",
      "for 200 data points: (Test) 3.1154552276926193\n",
      "for 300 data points: (Training)  2.742879899878274\n",
      "for 300 data points: (Test) 3.09854855135922\n",
      "for 400 data points: (Training)  2.7208194053761376\n",
      "for 400 data points: (Test) 3.1118050044162557\n",
      "for 500 data points: (Training)  2.77902926307626\n",
      "for 500 data points: (Test) 3.10044099031993\n",
      "for all data points: (Training)  2.879398584299829\n",
      "for all data points: (Test) 3.0865243377757547\n",
      "\n",
      "the more data I have, my error increases\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0ztFQrGaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a15e5bd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regressor.fit(X_train[:100], y_train[:100]) \n",
    "xtr1 = RMSE(regressor.predict(X_test), y_test)\n",
    "x1 = RMSE(regressor.predict(X_train[:100]), y_train[:100])\n",
    "print(\"for 100 data points: (Training) \", x1)\n",
    "print('for 100 data points: (Test)', xtr1) \n",
    "regressor.fit(X_train[:200], y_train[:200]) \n",
    "x2 = RMSE(regressor.predict(X_train[:200]), y_train[:200])\n",
    "xtr2 = RMSE(regressor.predict(X_test), y_test)\n",
    "print(\"for 200 data points: (Training) \", x2)\n",
    "print('for 200 data points: (Test)', RMSE(regressor.predict(X_test), y_test)) \n",
    "regressor.fit(X_train[:300], y_train[:300]) \n",
    "x3 = RMSE(regressor.predict(X_train[:300]), y_train[:300])\n",
    "xtr3 = RMSE(regressor.predict(X_test), y_test)\n",
    "print(\"for 300 data points: (Training) \", x3)\n",
    "print('for 300 data points: (Test)', RMSE(regressor.predict(X_test), y_test))\n",
    "regressor.fit(X_train[:400], y_train[:400]) \n",
    "x4 = RMSE(regressor.predict(X_train[:400]), y_train[:400])\n",
    "xtr4 = RMSE(regressor.predict(X_test), y_test)\n",
    "print(\"for 400 data points: (Training) \", x4)\n",
    "print('for 400 data points: (Test)', RMSE(regressor.predict(X_test), y_test)) \n",
    "regressor.fit(X_train[:500], y_train[:500]) \n",
    "x5 = RMSE(regressor.predict(X_train[:500]), y_train[:500])\n",
    "xtr5 = RMSE(regressor.predict(X_test), y_test)\n",
    "print(\"for 500 data points: (Training) \", x5)\n",
    "print('for 500 data points: (Test)', RMSE(regressor.predict(X_test), y_test)) \n",
    "regressor.fit(X_train, y_train) \n",
    "xall = RMSE(regressor.predict(X_train), y_train)\n",
    "xtrall = RMSE(regressor.predict(X_test), y_test)\n",
    "print(\"for all data points: (Training) \", xall)\n",
    "print('for all data points: (Test)', RMSE(regressor.predict(X_test), y_test)) \n",
    "print()\n",
    "print(\"the more data I have, my error increases\")\n",
    "\n",
    "value = [x1, x2, x3, x4, x5, xall]\n",
    "value2 = [xtr1, xtr2, xtr3, xtr4, xtr5, xtrall,]\n",
    "nums = [100, 200, 300, 400, 500, len(X_train)]\n",
    "\n",
    "\n",
    "plt.plot(nums, value, label = 'train')\n",
    "plt.plot(nums, value2, label = 'test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__CLASSIFICATION__:\n",
    "LABELS ARE DISCRETE VALUES.\n",
    "\n",
    "Here the model is trained to classify each instance into a set of predefined discrete classes. On inputting a feature vector into the model, the trained model is able to predict a class of that instance.\n",
    "\n",
    "Bucket the values of 'y1' i.e 'Heating Load'  from the original dataset into 3 classes:\n",
    "\n",
    "0: 'Low' ( < 14),   \n",
    "1: 'Medium'  (14-28),   \n",
    "2: 'High'  (>28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1     X2     X3      X4   X5  X6   X7  X8     Y1   class\n",
       "0  0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55  Medium\n",
       "1  0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55  Medium\n",
       "2  0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55  Medium\n",
       "3  0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55  Medium\n",
       "4  0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84  Medium"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'] = pd.cut(df[\"Y1\"], [0,14,28, np.inf], include_lowest = True, labels = [\"Low\", 'Medium', 'High'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['X1','X2','X3','X4','X5','X6','X7','X8']]\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 5)\n",
    "LogisticRegressionModel = linear_model.LogisticRegression()\n",
    "LogisticRegressionModel.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the training and test accuracies\n",
    "- Print the confusion matrix\n",
    "- Print the precision and recall numbers for all the classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8078175895765473\n",
      "Test Accuracy: 0.7857142857142857\n",
      "\n",
      "Confusion matrix of test data is: \n",
      "                Predicted Low  Predicted Medium  Predicted High\n",
      "Actual Low                56                 0               0\n",
      "Actual Medium              0                40               1\n",
      "Actual High               21                11              25\n",
      "\n",
      "Average precision for the 3 classes is -  [0.72727273 0.78431373 0.96153846]\n",
      "\n",
      "Average recall for the 3 classes is -  [1.         0.97560976 0.43859649]\n"
     ]
    }
   ],
   "source": [
    "training_accuracy=LogisticRegressionModel.score(X_train,y_train)\n",
    "print ('Training Accuracy:',training_accuracy)\n",
    "test_accuracy=LogisticRegressionModel.score(X_test,y_test)\n",
    "print ('Test Accuracy:',test_accuracy) \n",
    "print()\n",
    "y_true = y_test\n",
    "y_pred = LogisticRegressionModel.predict(X_test)\n",
    "ConfusionMatrix=pd.DataFrame(confusion_matrix(y_true, y_pred),columns=['Predicted Low','Predicted Medium','Predicted High'],index=['Actual Low','Actual Medium','Actual High'])\n",
    "print ('Confusion matrix of test data is: \\n',ConfusionMatrix)\n",
    "print()\n",
    "print(\"Average precision for the 3 classes is - \", precision_score(y_true, y_pred, average = None))\n",
    "print()\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Average recall for the 3 classes is - \", recall_score(y_true, y_pred, average = None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K Fold Cross Validation\n",
    "\n",
    " In k-fold cross-validation, the shuffled training data is partitioned into k disjoint sets and the model is trained on k âˆ’1 sets and validated on the kth set. This process is repeated k times with each set chosen as the validation set once. The cross-validation accuracy is reported as the average accuracy of the k iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [0.80909091 0.77272727 0.7        0.84545455 0.80909091 0.81651376\n",
      " 0.80733945]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7943166924818301"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['X1','X2','X3','X4','X5','X6','X7','X8']]\n",
    "y = df['class']\n",
    "F = KFold(n_splits=7, random_state=5, shuffle = True) \n",
    "LM = linear_model.LogisticRegression()\n",
    "scores = cross_val_score(LM, X, y, cv = F)\n",
    "print('Cross-validated scores:', scores)  \n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the preprocessing steps in Data science is Feature Scaling i.e getting all our data on the same scale by setting same  Min-Max of feature values. \n",
    "This makes training less sensitive to the scale of features . \n",
    "Scaling is important in algorithms that use distance functions as a part of classification. If we Scale features in the range [0,1] it is called unity based normalization.\n",
    "\n",
    "__Performing unity based normalization on the above dataset and train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8061889250814332\n",
      "Test Accuracy: 0.8311688311688312\n",
      "\n",
      "Confusion matrix of test data is: \n",
      "                Predicted Low  Predicted Medium  Predicted High\n",
      "Actual Low                56                 0               0\n",
      "Actual Medium              0                39               2\n",
      "Actual High               20                 4              33\n",
      "\n",
      "Average precision for the 3 classes is -  [0.73684211 0.90697674 0.94285714]\n",
      "\n",
      "Average recall for the 3 classes is -  [1.         0.95121951 0.57894737]\n"
     ]
    }
   ],
   "source": [
    "y = df['class']\n",
    "X = df[['X1','X2','X3','X4','X5','X6','X7','X8']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 5)\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_test_minmax = min_max_scaler.fit_transform(X_test)\n",
    "LogisticRegressionModel = linear_model.LogisticRegression()\n",
    "LogisticRegressionModel.fit(X_train_minmax, y_train) \n",
    "training_accuracy=LogisticRegressionModel.score(X_train_minmax,y_train)\n",
    "print ('Training Accuracy:',training_accuracy) \n",
    "test_accuracy=LogisticRegressionModel.score(X_test_minmax,y_test)\n",
    "print ('Test Accuracy:',test_accuracy) \n",
    "print()\n",
    "y_true = y_test\n",
    "y_pred = LogisticRegressionModel.predict(X_test_minmax)\n",
    "ConfusionMatrix=pd.DataFrame(confusion_matrix(y_true, y_pred),columns=['Predicted Low','Predicted Medium','Predicted High'],index=['Actual Low','Actual Medium','Actual High'])\n",
    "print ('Confusion matrix of test data is: \\n',ConfusionMatrix)\n",
    "print()\n",
    "print(\"Average precision for the 3 classes is - \", precision_score(y_true, y_pred, average = None))\n",
    "print()\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Average recall for the 3 classes is - \", recall_score(y_true, y_pred, average = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It works significantly better as compared to q2.2 for the test accuracy but the training accuracy is very slightly worse. It was 0.8078175895765473 for Training Accuracy before and 0.7857142857142857 Test Accuracy before.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'But if I change my random state to say a 100 I cansee my accuracies improve a lot. '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"It works significantly better as compared to q2.2 for the test accuracy but the training accuracy is very slightly worse. It was 0.8078175895765473 for Training Accuracy before and 0.7857142857142857 Test Accuracy before.\" )\n",
    "\"But if I change my random state to say a 100 I cansee my accuracies improve a lot. \""
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "data-x"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
